{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scheduler is an algorithm that provides instructions to the denoising process such as how much noise to remove at a certain step. It takes the model prediction from step *t* and applies an update for how to compute the next sample at step *t-1*. Different schedulers produce different results; some are faster while others are more accurate.\n",
    "\n",
    "Diffusers supports many schedulers and allows you to modify their timestep schedules, timestep spacing, and more, to generate high-quality images in fewer steps.\n",
    "\n",
    "This guide will show you how to load and customize schedulers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schedulers don't have any parameters and are defined in a configuration file. Access the `.scheduler` attribute of a pipeline to view the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, device_map=\"cuda\"\n",
    ")\n",
    "pipeline.scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a different scheduler with [from_pretrained()](https://huggingface.co/docs/diffusers/main/en/api/schedulers/overview#diffusers.SchedulerMixin.from_pretrained) and specify the `subfolder` argument to load the configuration file into the correct subfolder of the pipeline repository. Pass the new scheduler to the existing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "dpm = DPMSolverMultistepScheduler.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", subfolder=\"scheduler\"\n",
    ")\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    scheduler=dpm,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "pipeline.scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestep schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestep or noise schedule decides how noise is distributed over the denoising process. The schedule can be linear or more concentrated toward the beginning or end. It is a precomputed sequence of noise levels generated from the scheduler's default configuration, but it can be customized to use other schedules.\n",
    "\n",
    "> [!TIP]\n",
    "> The `timesteps` argument is only supported for a select list of schedulers and pipelines. Feel free to open a feature request if you want to extend these parameters to a scheduler and pipeline that does not currently support it!\n",
    "\n",
    "The example below uses the [Align Your Steps (AYS)](https://research.nvidia.com/labs/toronto-ai/AlignYourSteps/) schedule which can generate a high-quality image in 10 steps, significantly speeding up generation and reducing computation time.\n",
    "\n",
    "Import the schedule and pass it to the `timesteps` argument in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from diffusers.schedulers import AysSchedules\n",
    "\n",
    "sampling_schedule = AysSchedules[\"StableDiffusionXLTimesteps\"]\n",
    "print(sampling_schedule)\n",
    "\"[999, 845, 730, 587, 443, 310, 193, 116, 53, 13]\"\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"SG161222/RealVisXL_V4.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "  pipeline.scheduler.config, algorithm_type=\"sde-dpmsolver++\"\n",
    ")\n",
    "\n",
    "prompt = \"A cinematic shot of a cute little rabbit wearing a jacket and doing a thumbs up\"\n",
    "image = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=\"\",\n",
    "    timesteps=sampling_schedule,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex gap-4\">\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/ays.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">AYS timestep schedule 10 steps</figcaption>\n",
    "  </div>\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/10.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">Linearly-spaced timestep schedule 10 steps</figcaption>\n",
    "  </div>\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/25.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">Linearly-spaced timestep schedule 25 steps</figcaption>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising should begin with pure noise and the signal-to-noise (SNR) ration should be zero. However, some models don't actually start from pure noise which makes it difficult to generate images at brightness extremes.\n",
    "\n",
    "> [!TIP]\n",
    "> Train your own model with `v_prediction` by adding the `--prediction_type=\"v_prediction\"` flag to your training script. You can also [search](https://huggingface.co/search/full-text?q=v_prediction&type=model) for existing models trained with `v_prediction`.\n",
    "\n",
    "To fix this, a model must be trained with `v_prediction`. If a model is trained with `v_prediction`, then enable the following arguments in the scheduler.\n",
    "\n",
    "- Set `rescale_betas_zero_snr=True` to rescale the noise schedule to the very last timestep with exactly zero SNR\n",
    "- Set `timestep_spacing=\"trailing\"` to force sampling from the last timestep with pure noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, DDIMScheduler\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"ptx0/pseudo-journey-v2\", device_map=\"cuda\")\n",
    "\n",
    "pipeline.scheduler = DDIMScheduler.from_config(\n",
    "    pipeline.scheduler.config, rescale_betas_zero_snr=True, timestep_spacing=\"trailing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `guidance_rescale` in the pipeline to avoid overexposed images. A lower value increases brightness, but some details may appear washed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "cinematic photo of a snowy mountain at night with the northern lights aurora borealis\n",
    "overhead, 35mm photograph, film, professional, 4k, highly detailed\n",
    "\"\"\"\n",
    "image = pipeline(prompt, guidance_rescale=0.7).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex gap-4\">\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/no-zero-snr.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">default Stable Diffusion v2-1 image</figcaption>\n",
    "  </div>\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/zero-snr.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">image with zero SNR and trailing timestep spacing enabled</figcaption>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestep spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestep spacing refers to the specific steps *t* to sample from from the schedule. Diffusers provides three spacing types as shown below.\n",
    "\n",
    "| spacing strategy | spacing calculation | example timesteps |\n",
    "|---|---|---|\n",
    "| `leading` | evenly spaced steps | `[900, 800, 700, ..., 100, 0]` |\n",
    "| `linspace` | include first and last steps and evenly divide remaining intermediate steps | `[1000, 888.89, 777.78, ..., 111.11, 0]` |\n",
    "| `trailing` | include last step and evenly divide remaining intermediate steps beginning from the end | `[999, 899, 799, 699, 599, 499, 399, 299, 199, 99]` |\n",
    "\n",
    "Pass the spacing strategy to the `timestep_spacing` argument in the scheduler.\n",
    "\n",
    "> [!TIP]\n",
    "> The `trailing` strategy typically produces higher quality images with more details with fewer steps, but the difference in quality is not as obvious for more standard step values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"SG161222/RealVisXL_V4.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "  pipeline.scheduler.config, timestep_spacing=\"trailing\"\n",
    ")\n",
    "\n",
    "prompt = \"A cinematic shot of a cute little black cat sitting on a pumpkin at night\"\n",
    "image = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=\"\",\n",
    "    num_inference_steps=5,\n",
    ").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex gap-4\">\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/trailing_spacing.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">trailing spacing after 5 steps</figcaption>\n",
    "  </div>\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/leading_spacing.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">leading spacing after 5 steps</figcaption>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmas is a measure of how noisy a sample is at a certain step as defined by the schedule. When using custom `sigmas`, the `timesteps` are calculated from these values instead of the default scheduler configuration.\n",
    "\n",
    "> [!TIP]\n",
    "> The `sigmas` argument is only supported for a select list of schedulers and pipelines. Feel free to open a feature request if you want to extend these parameters to a scheduler and pipeline that does not currently support it!\n",
    "\n",
    "Pass the custom sigmas to the `sigmas` argument in the pipeline. The example below uses the [sigmas](https://github.com/huggingface/diffusers/blob/6529ee67ec02fcf58d2fd9242164ea002b351d75/src/diffusers/schedulers/scheduling_utils.py#L55) from the 10-step AYS schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"SG161222/RealVisXL_V4.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "  pipeline.scheduler.config, algorithm_type=\"sde-dpmsolver++\"\n",
    ")\n",
    "\n",
    "sigmas = [14.615, 6.315, 3.771, 2.181, 1.342, 0.862, 0.555, 0.380, 0.234, 0.113, 0.0]\n",
    "prompt = \"A cinematic shot of a cute little rabbit wearing a jacket and doing a thumbs up\"\n",
    "image = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=\"\",\n",
    "    sigmas=sigmas,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Karras sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Karras sigmas](https://huggingface.co/papers/2206.00364) resamples the noise schedule for more efficient sampling by clustering sigmas more densely in the middle of the sequence where structure reconstruction is critical, while using fewer sigmas at the beginning and end where noise changes have less impact. This can increase the level of details in a generated image.\n",
    "\n",
    "Set `use_karras_sigmas=True` in the scheduler to enable it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"SG161222/RealVisXL_V4.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "  pipeline.scheduler.config,\n",
    "  algorithm_type=\"sde-dpmsolver++\",\n",
    "  use_karras_sigmas=True,\n",
    ")\n",
    "\n",
    "prompt = \"A cinematic shot of a cute little rabbit wearing a jacket and doing a thumbs up\"\n",
    "image = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=\"\",\n",
    "    sigmas=sigmas,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex gap-4\">\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/karras_sigmas_true.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">Karras sigmas enabled</figcaption>\n",
    "  </div>\n",
    "  <div>\n",
    "    <img class=\"rounded-xl\" src=\"https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/karras_sigmas_false.png\"/>\n",
    "    <figcaption class=\"mt-2 text-center text-sm text-gray-500\">Karras sigmas disabled</figcaption>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "Refer to the scheduler API [overview](https://huggingface.co/docs/diffusers/main/en/using-diffusers/../api/schedulers/overview) for a list of schedulers that support Karras sigmas. It should only be used for models trained with Karras sigmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to try different schedulers to find the best one for your use case. Here are a few recommendations to help you get started.\n",
    "\n",
    "- DPM++ 2M SDE Karras is generally a good all-purpose option.\n",
    "- [TCDScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/tcd#diffusers.TCDScheduler) works well for distilled models.\n",
    "- [FlowMatchEulerDiscreteScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/flow_match_euler_discrete#diffusers.FlowMatchEulerDiscreteScheduler) and [FlowMatchHeunDiscreteScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/flow_match_heun_discrete#diffusers.FlowMatchHeunDiscreteScheduler) for FlowMatch models.\n",
    "- [EulerDiscreteScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler) or [EulerAncestralDiscreteScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/euler_ancestral#diffusers.EulerAncestralDiscreteScheduler) for generating anime style images.\n",
    "- DPM++ 2M paired with [LCMScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/lcm#diffusers.LCMScheduler) on SDXL for generating realistic images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the [Common Diffusion Noise Schedules and Sample Steps are Flawed](https://huggingface.co/papers/2305.08891) paper for more details about rescaling the noise schedule to enforce zero SNR."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
