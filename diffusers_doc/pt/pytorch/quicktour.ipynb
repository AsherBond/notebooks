{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tour r√°pido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos de difus√£o s√£o treinados para remover o ru√≠do Gaussiano aleat√≥rio passo a passo para gerar uma amostra de interesse, como uma imagem ou √°udio. Isso despertou um tremendo interesse em IA generativa, e voc√™ provavelmente j√° viu exemplos de imagens geradas por difus√£o na internet. üß® Diffusers √© uma biblioteca que visa tornar os modelos de difus√£o amplamente acess√≠veis a todos.\n",
    "\n",
    "Seja voc√™ um desenvolvedor ou um usu√°rio, esse tour r√°pido ir√° introduzir voc√™ ao üß® Diffusers e ajudar voc√™ a come√ßar a gerar rapidamente! H√° tr√™s componentes principais da biblioteca para conhecer:\n",
    "\n",
    "- O `DiffusionPipeline` √© uma classe de alto n√≠vel de ponta a ponta desenhada para gerar rapidamente amostras de modelos de difus√£o pr√©-treinados para infer√™ncia.\n",
    "- [Modelos](https://huggingface.co/docs/diffusers/main/pt/./api/models) pr√©-treinados populares e m√≥dulos que podem ser usados como blocos de constru√ß√£o para criar sistemas de difus√£o.\n",
    "- V√°rios [Agendadores](https://huggingface.co/docs/diffusers/main/pt/./api/schedulers/overview) diferentes - algoritmos que controlam como o ru√≠do √© adicionado para treinamento, e como gerar imagens sem o ru√≠do durante a infer√™ncia.\n",
    "\n",
    "Esse tour r√°pido mostrar√° como usar o `DiffusionPipeline` para infer√™ncia, e ent√£o mostrar√° como combinar um modelo e um agendador para replicar o que est√° acontecendo dentro do `DiffusionPipeline`.\n",
    "\n",
    "> [!TIP]\n",
    "> Esse tour r√°pido √© uma vers√£o simplificada da introdu√ß√£o üß® Diffusers [notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb) para ajudar voc√™ a come√ßar r√°pido. Se voc√™ quer aprender mais sobre o objetivo do üß® Diffusers, filosofia de design, e detalhes adicionais sobre a API principal, veja o notebook!\n",
    "\n",
    "Antes de come√ßar, certifique-se de ter todas as bibliotecas necess√°rias instaladas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install the necessary libraries in Colab\n",
    "#!pip install --upgrade diffusers accelerate transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ü§ó Accelerate](https://huggingface.co/docs/accelerate/index) acelera o carregamento do modelo para gera√ß√£o e treinamento.\n",
    "- [ü§ó Transformers](https://huggingface.co/docs/transformers/index) √© necess√°rio para executar os modelos mais populares de difus√£o, como o [Stable Diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DiffusionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `DiffusionPipeline` √© a forma mais f√°cil de usar um sistema de difus√£o pr√©-treinado para gera√ß√£o. √â um sistema de ponta a ponta contendo o modelo e o agendador. Voc√™ pode usar o `DiffusionPipeline` pronto para muitas tarefas. D√™ uma olhada na tabela abaixo para algumas tarefas suportadas, e para uma lista completa de tarefas suportadas, veja a tabela [Resumo do üß® Diffusers](https://huggingface.co/docs/diffusers/main/pt/./api/pipelines/overview#diffusers-summary).\n",
    "\n",
    "| **Tarefa**                             | **Descri√ß√£o**                                                                                                             | **Pipeline**                                                                       |\n",
    "| -------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |\n",
    "| Unconditional Image Generation         | gera uma imagem a partir do ru√≠do Gaussiano                                                                               | [unconditional_image_generation](https://huggingface.co/docs/diffusers/main/pt/./using-diffusers/unconditional_image_generation) |\n",
    "| Text-Guided Image Generation           | gera uma imagem a partir de um prompt de texto                                                                            | [conditional_image_generation](https://huggingface.co/docs/diffusers/main/pt/./using-diffusers/conditional_image_generation)     |\n",
    "| Text-Guided Image-to-Image Translation | adapta uma imagem guiada por um prompt de texto                                                                           | [img2img](https://huggingface.co/docs/diffusers/main/pt/./using-diffusers/img2img)                                               |\n",
    "| Text-Guided Image-Inpainting           | preenche a parte da m√°scara da imagem, dado a imagem, a m√°scara e o prompt de texto                                       | [inpaint](https://huggingface.co/docs/diffusers/main/pt/./using-diffusers/inpaint)                                               |\n",
    "| Text-Guided Depth-to-Image Translation | adapta as partes de uma imagem guiada por um prompt de texto enquanto preserva a estrutura por estimativa de profundidade | [depth2img](https://huggingface.co/docs/diffusers/main/pt/./using-diffusers/depth2img)                                           |\n",
    "\n",
    "Comece criando uma inst√¢ncia do `DiffusionPipeline` e especifique qual checkpoint do pipeline voc√™ gostaria de baixar.\n",
    "Voc√™ pode usar o `DiffusionPipeline` para qualquer [checkpoint](https://huggingface.co/models?library=diffusers&sort=downloads) armazenado no Hugging Face Hub.\n",
    "Nesse quicktour, voc√™ carregar√° o checkpoint [`stable-diffusion-v1-5`](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5) para gera√ß√£o de texto para imagem.\n",
    "\n",
    "> [!WARNING]\n",
    "> Para os modelos de [Stable Diffusion](https://huggingface.co/CompVis/stable-diffusion), por favor leia cuidadosamente a [licen√ßa](https://huggingface.co/spaces/CompVis/stable-diffusion-license) primeiro antes de rodar o modelo. üß® Diffusers implementa uma verifica√ß√£o de seguran√ßa: [`safety_checker`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py) para prevenir conte√∫do ofensivo ou nocivo, mas as capacidades de gera√ß√£o de imagem aprimorada do modelo podem ainda produzir conte√∫do potencialmente nocivo.\n",
    "\n",
    "Para carregar o modelo com o m√©todo `from_pretrained()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\", use_safetensors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `DiffusionPipeline` baixa e armazena em cache todos os componentes de modelagem, tokeniza√ß√£o, e agendamento. Voc√™ ver√° que o pipeline do Stable Diffusion √© composto pelo `UNet2DConditionModel` e `PNDMScheduler` entre outras coisas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StableDiffusionPipeline {\n",
       "  \"_class_name\": \"StableDiffusionPipeline\",\n",
       "  \"_diffusers_version\": \"0.13.1\",\n",
       "  ...,\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  ...,\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√≥s fortemente recomendamos rodar o pipeline em uma placa de v√≠deo, pois o modelo consiste em aproximadamente 1.4 bilh√µes de par√¢metros.\n",
    "Voc√™ pode mover o objeto gerador para uma placa de v√≠deo, assim como voc√™ faria no PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora voc√™ pode passar o prompt de texto para o `pipeline` para gerar uma imagem, e ent√£o acessar a imagem sem ru√≠do. Por padr√£o, a sa√≠da da imagem √© embrulhada em um objeto [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=image#the-image-class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipeline(\"An image of a squirrel in Picasso style\").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_of_squirrel_painting.png\"/>\n",
    "</div>\n",
    "\n",
    "Salve a imagem chamando o `save`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.save(\"image_of_squirrel_painting.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voc√™ tamb√©m pode utilizar o pipeline localmente. A √∫nica diferen√ßa √© que voc√™ precisa baixar os pesos primeiro:\n",
    "\n",
    "```bash\n",
    "!git lfs install\n",
    "!git clone https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5\n",
    "```\n",
    "\n",
    "Assim carregue os pesos salvos no pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(\"./stable-diffusion-v1-5\", use_safetensors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora voc√™ pode rodar o pipeline como voc√™ faria na se√ß√£o acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troca dos agendadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agendadores diferentes tem diferentes velocidades de retirar o ru√≠do e compensa√ß√µes de qualidade. A melhor forma de descobrir qual funciona melhor para voc√™ √© testar eles! Uma das principais caracter√≠sticas do üß® Diffusers √© permitir que voc√™ troque facilmente entre agendadores. Por exemplo, para substituir o `PNDMScheduler` padr√£o com o `EulerDiscreteScheduler`, carregue ele com o m√©todo `from_config()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import EulerDiscreteScheduler\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\", use_safetensors=True)\n",
    "pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tente gerar uma imagem com o novo agendador e veja se voc√™ nota alguma diferen√ßa!\n",
    "\n",
    "Na pr√≥xima se√ß√£o, voc√™ ir√° dar uma olhada mais de perto nos componentes - o modelo e o agendador - que comp√µe o `DiffusionPipeline` e aprender como usar esses componentes para gerar uma imagem de um gato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria dos modelos recebe uma amostra de ru√≠do, e em cada _timestep_ ele prev√™ o _noise residual_ (outros modelos aprendem a prever a amostra anterior diretamente ou a velocidade ou [`v-prediction`](https://github.com/huggingface/diffusers/blob/5e5ce13e2f89ac45a0066cb3f369462a3cf1d9ef/src/diffusers/schedulers/scheduling_ddim.py#L110)), a diferen√ßa entre uma imagem menos com ru√≠do e a imagem de entrada. Voc√™ pode misturar e combinar modelos para criar outros sistemas de difus√£o.\n",
    "\n",
    "Modelos s√£o inicializados com o m√©todo `from_pretrained()` que tamb√©m armazena em cache localmente os pesos do modelo para que seja mais r√°pido na pr√≥xima vez que voc√™ carregar o modelo. Para o tour r√°pido, voc√™ ir√° carregar o `UNet2DModel`, um modelo b√°sico de gera√ß√£o de imagem incondicional com um checkpoint treinado em imagens de gato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "\n",
    "repo_id = \"google/ddpm-cat-256\"\n",
    "model = UNet2DModel.from_pretrained(repo_id, use_safetensors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acessar os par√¢metros do modelo, chame `model.config`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A configura√ß√£o do modelo √© um dicion√°rio üßä congelado üßä, o que significa que esses par√¢metros n√£o podem ser mudados depois que o modelo √© criado. Isso √© intencional e garante que os par√¢metros usados para definir a arquitetura do modelo no in√≠cio permane√ßam os mesmos, enquanto outros par√¢metros ainda podem ser ajustados durante a gera√ß√£o.\n",
    "\n",
    "Um dos par√¢metros mais importantes s√£o:\n",
    "\n",
    "- `sample_size`: a dimens√£o da altura e largura da amostra de entrada.\n",
    "- `in_channels`: o n√∫mero de canais de entrada da amostra de entrada.\n",
    "- `down_block_types` e `up_block_types`: o tipo de blocos de downsampling e upsampling usados para criar a arquitetura UNet.\n",
    "- `block_out_channels`: o n√∫mero de canais de sa√≠da dos blocos de downsampling; tamb√©m utilizado como uma order reversa do n√∫mero de canais de entrada dos blocos de upsampling.\n",
    "- `layers_per_block`: o n√∫mero de blocks ResNet presentes em cada block UNet.\n",
    "\n",
    "Para usar o modelo para gera√ß√£o, crie a forma da imagem com ru√≠do Gaussiano aleat√≥rio. Deve ter um eixo `batch` porque o modelo pode receber m√∫ltiplos ru√≠dos aleat√≥rios, um eixo `channel` correspondente ao n√∫mero de canais de entrada, e um eixo `sample_size` para a altura e largura da imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "noisy_sample = torch.randn(1, model.config.in_channels, model.config.sample_size, model.config.sample_size)\n",
    "noisy_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para gera√ß√£o, passe a imagem com ru√≠do para o modelo e um `timestep`. O `timestep` indica o qu√£o ruidosa a imagem de entrada √©, com mais ru√≠do no in√≠cio e menos no final. Isso ajuda o modelo a determinar sua posi√ß√£o no processo de difus√£o, se est√° mais perto do in√≠cio ou do final. Use o m√©todo `sample` para obter a sa√≠da do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noisy_residual = model(sample=noisy_sample, timestep=2).sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para gera√ß√£o de exemplos reais, voc√™ precisar√° de um agendador para guiar o processo de retirada do ru√≠do. Na pr√≥xima se√ß√£o, voc√™ ir√° aprender como acoplar um modelo com um agendador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agendadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agendadores gerenciam a retirada do ru√≠do de uma amostra ruidosa para uma amostra menos ruidosa dado a sa√≠da do modelo - nesse caso, √© o `noisy_residual`.\n",
    "\n",
    "> [!TIP]\n",
    "> üß® Diffusers √© uma caixa de ferramentas para construir sistemas de difus√£o. Enquanto o `DiffusionPipeline` √© uma forma conveniente de come√ßar com um sistema de difus√£o pr√©-constru√≠do, voc√™ tamb√©m pode escolher seus pr√≥prios modelos e agendadores separadamente para construir um sistema de difus√£o personalizado.\n",
    "\n",
    "Para o tour r√°pido, voc√™ ir√° instanciar o `DDPMScheduler` com o m√©todo `from_config()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDPMScheduler {\n",
       "  \"_class_name\": \"DDPMScheduler\",\n",
       "  \"_diffusers_version\": \"0.13.1\",\n",
       "  \"beta_end\": 0.02,\n",
       "  \"beta_schedule\": \"linear\",\n",
       "  \"beta_start\": 0.0001,\n",
       "  \"clip_sample\": true,\n",
       "  \"clip_sample_range\": 1.0,\n",
       "  \"num_train_timesteps\": 1000,\n",
       "  \"prediction_type\": \"epsilon\",\n",
       "  \"trained_betas\": null,\n",
       "  \"variance_type\": \"fixed_small\"\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "\n",
    "scheduler = DDPMScheduler.from_config(repo_id)\n",
    "scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!TIP]\n",
    "> üí° Perceba como o agendador √© instanciado de uma configura√ß√£o. Diferentemente de um modelo, um agendador n√£o tem pesos trein√°veis e √© livre de par√¢metros!\n",
    "\n",
    "Um dos par√¢metros mais importante s√£o:\n",
    "\n",
    "- `num_train_timesteps`: o tamanho do processo de retirar ru√≠do ou em outras palavras, o n√∫mero de _timesteps_ necess√°rios para o processo de ru√≠dos Gausianos aleat√≥rios dentro de uma amostra de dados.\n",
    "- `beta_schedule`: o tipo de agendados de ru√≠do para o uso de gera√ß√£o e treinamento.\n",
    "- `beta_start` e `beta_end`: para come√ßar e terminar os valores de ru√≠do para o agendador de ru√≠do.\n",
    "\n",
    "Para predizer uma imagem com um pouco menos de ru√≠do, passe o seguinte para o m√©todo do agendador `step()`: sa√≠da do modelo, `timestep`, e a atual `amostra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=2, sample=noisy_sample).prev_sample\n",
    "less_noisy_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `less_noisy_sample` pode ser passado para o pr√≥ximo `timestep` onde ele ficar√° ainda com menos ru√≠do! Vamos juntar tudo agora e visualizar o processo inteiro de retirada de ru√≠do.\n",
    "\n",
    "Comece, criando a fun√ß√£o que fa√ßa o p√≥s-processamento e mostre a imagem sem ru√≠do como uma `PIL.Image`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def display_sample(sample, i):\n",
    "    image_processed = sample.cpu().permute(0, 2, 3, 1)\n",
    "    image_processed = (image_processed + 1.0) * 127.5\n",
    "    image_processed = image_processed.numpy().astype(np.uint8)\n",
    "\n",
    "    image_pil = PIL.Image.fromarray(image_processed[0])\n",
    "    display(f\"Image at step {i}\")\n",
    "    display(image_pil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acelerar o processo de retirada de ru√≠do, mova a entrada e o modelo para uma GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\")\n",
    "noisy_sample = noisy_sample.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, crie um loop de retirada de ru√≠do que prediz o residual da amostra menos ruidosa, e computa a amostra menos ruidosa com o agendador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "sample = noisy_sample\n",
    "\n",
    "for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):\n",
    "    # 1. predict noise residual\n",
    "    with torch.no_grad():\n",
    "        residual = model(sample, t).sample\n",
    "\n",
    "    # 2. compute less noisy image and set x_t -> x_t-1\n",
    "    sample = scheduler.step(residual, t, sample).prev_sample\n",
    "\n",
    "    # 3. optionally look at image\n",
    "    if (i + 1) % 50 == 0:\n",
    "        display_sample(sample, i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sente-se e assista o gato ser gerado do nada al√©m de ru√≠do! üòª\n",
    "\n",
    "<div class=\"flex justify-center\">\n",
    "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/diffusion-quicktour.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√≥ximos passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esperamos que voc√™ tenha gerado algumas imagens legais com o üß® Diffusers neste tour r√°pido! Para suas pr√≥ximas etapas, voc√™ pode\n",
    "\n",
    "- Treine ou fa√ßa a configura√ß√£o fina de um modelo para gerar suas pr√≥prias imagens no tutorial de [treinamento](https://huggingface.co/docs/diffusers/main/pt/./tutorials/basic_training).\n",
    "- Veja exemplos oficiais e da comunidade de [scripts de treinamento ou configura√ß√£o fina](https://github.com/huggingface/diffusers/tree/main/examples#-diffusers-examples) para os mais variados casos de uso.\n",
    "- Aprenda sobre como carregar, acessar, mudar e comparar agendadores no guia [Usando diferentes agendadores](https://huggingface.co/docs/diffusers/main/pt/./using-diffusers/schedulers).\n",
    "- Explore engenharia de prompt, otimiza√ß√µes de velocidade e mem√≥ria, e dicas e truques para gerar imagens de maior qualidade com o guia [Stable Diffusion](https://huggingface.co/docs/diffusers/main/pt/./stable_diffusion).\n",
    "- Se aprofunde em acelerar üß® Diffusers com guias sobre [PyTorch otimizado em uma GPU](https://huggingface.co/docs/diffusers/main/pt/./optimization/fp16), e guias de infer√™ncia para rodar [Stable Diffusion em Apple Silicon (M1/M2)](https://huggingface.co/docs/diffusers/main/pt/./optimization/mps) e [ONNX Runtime](https://huggingface.co/docs/diffusers/main/pt/./optimization/onnx)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
